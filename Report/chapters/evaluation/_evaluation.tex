\chapter{Evaluation}
The evaluation is done in regards to the final networks created and their fulfilment of the requirements. As stated in \autoref{ch:req}, the networks must have a precision of $99\%$ or higher to be comparable to the state of the art networks being used now.

In order to comply with the demands for the input data used for training the systems mentioned in \autoref{ch:req}, the database Warsaw BioBase created by \cite{Trokielewicz2016}, which contains \gls{vl} images of irises obtained with a smart phone is used. The smart phone used was an iPhone 5s with an 8 megapixel camera, which is comparable to the resolution of the front facing cameras in the newest smart phones on the market. 

The first attempt of obtaining an acceptable accuracy was a unimodal iris classification system using regular machine learning. With this approach it was not possible to reach as high an accuracy as of the state of the art. The best performance achieved was when using a polynomial kernel for the \gls{svm}, which resulted in an accuracy of 98\%. However, the model had a training accuracy of 100\%, thus maybe the model is over fitting. A way to improve this could be training on more data in order to get a more generalised model. Another thing that could be investigated is the polynomial kernel applied, which in this case was defined as a third degree polynomial. However, it is possible that a polynomial of a different degree would map the data to a space where it was better separable by linear hyperplanes. 

Nonetheless, because of the insufficient accuracy obtained and the objective of the project, deep learning was taken into consideration as a solution. A \gls{cnn} consisting of 14 layers in total was implemented for iris classification. The \gls{cnn} was trained on the same database used for the machine learning method implemented and managed to reach an accuracy of $99.7\%$, which satisfies the requirement. The design of this is shown in \autoref{ch:implementation}.

The face recognition \gls{cnn} is based on the VGG16 network and uses the \gls{lfw} database for testing. By using the pre-trained weights from ImageNet trained on 2000 classes it is possible to reach an accuracy of $99.35\%$. The design of this is shown in \autoref{ch:implementation}.	

To try and achieve a better classifier the iris \gls{cnn} and face \gls{cnn} were merged into a fusion net. The network was fed with a synthetically created database where iris' images from Warsaw BioBase were paired with a face image from \gls{lfw} and given the same label. The network achieved an accuracy of 81.17\% on the test set.  Even though the training loss and validation loss are close to each other it seems like the net is overfitting a bit. Dropout layers and normalisation have already been applied to reduce the overfitting. To try and further reduce it different regularization for the loss function could be used.

The fusion net performs significantly worse than both of the individual \gls{cnn}s. To investigate the reason behind the sudden drop in accuracy the unimodal \gls{cnn}s were trained by using the synthetic chimeric data. The accuracy of both nets had dropped substantially with iris being at 68.94\% and face at 77.78\% on the test set. This is peculiar behaviour since they were previously trained trained with the data that was used to create the chimeric database. It could indicate that something has gone wrong in the merger of the Warsaw BioBase and \gls{lfw} data sets. Further investigation is needed. But in any case the fusion nets seems to perform better than the individual nets when they are trained on the same data. This could be an indication that with a multimodal database of face and iris, the fusion net could perform better. 